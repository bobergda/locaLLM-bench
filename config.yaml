ollama_host: "http://localhost:11434"
models:
  - "magistral:24b"
  - "gpt-oss:20b"
  - "qwen3:14b"
  - "qwen3:8b"
tests_dir: "tests"
debug: true
debug_models: [ "qwen3:14b"]
debug_test_sets: [ "code" ]
debug_task_limit: 1

# SECURITY: executing model-produced code is dangerous. Keep this false unless you trust `results.json`.
unsafe_code_exec: true

# Hard timeout for `code_tests` execution (seconds). Timeouts fail the test.
code_test_timeout_s: 2.0

# Optional Ollama generation options passed as `options` to `client.generate(...)`.
# Common keys: temperature, seed, num_ctx, top_p, top_k, repeat_penalty.
generate_options: {}
